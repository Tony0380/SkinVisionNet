{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# SkinVisionNet\n",
    "Deep Learning Techniques for Accurate Pigmented Skin Lesion Classification\n",
    "\n"
   ],
   "id": "94a420f4a4be1a66"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dataset retrieval\n",
    "\n",
    "_Link Dataset:_ https://www.kaggle.com/datasets/wanderdust/skin-lesion-analysis-toward-melanoma-detection/data\n"
   ],
   "id": "811546e46b9029eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T13:46:36.708701Z",
     "start_time": "2025-05-10T13:24:08.699852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kagglehub\n",
    "import outputs\n",
    "\n",
    "path = kagglehub.dataset_download(\"wanderdust/skin-lesion-analysis-toward-melanoma-detection\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n"
   ],
   "id": "1bc202bcf249f97e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colam\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming download from 333447168 bytes (11810070343 bytes left)...\n",
      "Resuming download from https://www.kaggle.com/api/v1/datasets/download/wanderdust/skin-lesion-analysis-toward-melanoma-detection?dataset_version_number=1 (333447168/12143517511) bytes left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11.3G/11.3G [20:39<00:00, 9.53MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\colam\\.cache\\kagglehub\\datasets\\wanderdust\\skin-lesion-analysis-toward-melanoma-detection\\versions\\1\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Using Dataset from local path\n",
    "\n"
   ],
   "id": "29c506560918ab41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T14:03:45.583394Z",
     "start_time": "2025-05-10T14:03:45.558613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "data_dir = \"skin-lesions\"\n",
    "\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "val_dir = os.path.join(data_dir, \"valid\")  #\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "# Normalizzazione standard per modelli preaddestrati su ImageNet\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Data augmentation per il training\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
    "])\n",
    "\n",
    "# Transform per validation e test\n",
    "test_val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
    "])\n",
    "\n",
    "# Dataset aggiornati\n",
    "train_dataset = ImageFolder(root=train_dir, transform=train_transform)\n",
    "val_dataset = ImageFolder(root=val_dir, transform=test_val_transform)\n",
    "test_dataset = ImageFolder(root=test_dir, transform=test_val_transform)\n"
   ],
   "id": "148e7ab6d83a3f81",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Loader setup",
   "id": "eb7621562634538c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T14:09:21.962315Z",
     "start_time": "2025-05-10T14:09:21.957575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32  # Puoi modificare questo valore in base alle risorse disponibili\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n"
   ],
   "id": "9b9f99ac84cf4e08",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fine tuning on Swin Transformer",
   "id": "40a0a224d76db037"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T14:35:35.063801Z",
     "start_time": "2025-05-10T14:35:33.921309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import timm\n",
    "import torch.nn as nn\n",
    "\n",
    "# Determina il numero di classi per la classificazione\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "# Carica del modello Swin Transformer pre-addestrato\n",
    "model = timm.create_model(\"swin_tiny_patch4_window7_224\", pretrained=True, num_classes=num_classes)\n"
   ],
   "id": "577bc0e179496069",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T14:35:42.677975Z",
     "start_time": "2025-05-10T14:35:42.660783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)"
   ],
   "id": "7a8a9ed406fcd2df",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T15:02:45.927038Z",
     "start_time": "2025-05-10T15:02:45.922514Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.cuda.is_available())\n",
   "id": "e4fb17846f18d636",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T15:02:35.520721Z",
     "start_time": "2025-05-10T15:02:35.470125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss, correct = 0.0, 0\n",
    "\n",
    "    for inputs, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # ðŸ” Debug temporaneo\n",
    "        print(\"Outputs shape:\", outputs.shape)\n",
    "        print(\"Labels shape:\", labels.shape)\n",
    "        break  # fermiamo al primo batch solo per analizzare\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += int((preds == labels).sum())\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = correct / len(dataloader.dataset)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss, correct = 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Validation\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = correct / len(dataloader.dataset)\n",
    "    return epoch_loss, epoch_acc\n"
   ],
   "id": "3f1d4a0328b97ede",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T14:45:32.906975Z",
     "start_time": "2025-05-10T14:35:46.499385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "**best_val_acc = 0.0\n",
    "n_epochs = 10\n",
    "model_path = \"best_swin_model.pt\"\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{n_epochs}\")\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"ðŸ“¦ Model saved: {model_path}\")\n",
    "\n",
    "\n"
   ],
   "id": "ac9e0dc4bc61a13f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: torch.Size([32, 3])\n",
      "Labels shape: torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/63 [00:27<?, ?it/s]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:26<00:00,  5.21s/it]\n",
      "C:\\Users\\colam\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0000, Accuracy: 0.0000\n",
      "Val   Loss: 1.0827, Accuracy: 0.3800\n",
      "ðŸ“¦ Model saved: best_swin_model.pt\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: torch.Size([32, 3])\n",
      "Labels shape: torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/63 [00:27<?, ?it/s]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:27<00:00,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0000, Accuracy: 0.0000\n",
      "Val   Loss: 1.0827, Accuracy: 0.3800\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: torch.Size([32, 3])\n",
      "Labels shape: torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/63 [00:27<?, ?it/s]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:27<00:00,  5.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0000, Accuracy: 0.0000\n",
      "Val   Loss: 1.0827, Accuracy: 0.3800\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: torch.Size([32, 3])\n",
      "Labels shape: torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/63 [00:28<?, ?it/s]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:33<00:00,  6.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0000, Accuracy: 0.0000\n",
      "Val   Loss: 1.0827, Accuracy: 0.3800\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: torch.Size([32, 3])\n",
      "Labels shape: torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/63 [00:31<?, ?it/s]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:30<00:00,  6.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0000, Accuracy: 0.0000\n",
      "Val   Loss: 1.0827, Accuracy: 0.3800\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: torch.Size([32, 3])\n",
      "Labels shape: torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/63 [00:26<?, ?it/s]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:31<00:00,  6.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0000, Accuracy: 0.0000\n",
      "Val   Loss: 1.0827, Accuracy: 0.3800\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: torch.Size([32, 3])\n",
      "Labels shape: torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/63 [00:34<?, ?it/s]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:28<00:00,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0000, Accuracy: 0.0000\n",
      "Val   Loss: 1.0827, Accuracy: 0.3800\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: torch.Size([32, 3])\n",
      "Labels shape: torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/63 [00:28<?, ?it/s]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:28<00:00,  5.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0000, Accuracy: 0.0000\n",
      "Val   Loss: 1.0827, Accuracy: 0.3800\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: torch.Size([32, 3])\n",
      "Labels shape: torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/63 [00:27<?, ?it/s]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:27<00:00,  5.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0000, Accuracy: 0.0000\n",
      "Val   Loss: 1.0827, Accuracy: 0.3800\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: torch.Size([32, 3])\n",
      "Labels shape: torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/63 [00:27<?, ?it/s]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:37<00:00,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0000, Accuracy: 0.0000\n",
      "Val   Loss: 1.0827, Accuracy: 0.3800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T15:08:33.848904Z",
     "start_time": "2025-05-10T15:07:02.514803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Carica il modello migliore\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"\\nðŸŽ¯ Test Accuracy: {test_acc:.4f} | Loss: {test_loss:.4f}\")\n"
   ],
   "id": "e62f6a777b29f503",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [01:31<00:00,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ Test Accuracy: 0.3017 | Loss: 1.1340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 50
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
